{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d77e911",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 05:35:14.289942: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-29 05:35:14.300587: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751175314.318523    2783 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751175314.323404    2783 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1751175314.333930    2783 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751175314.333947    2783 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751175314.333948    2783 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751175314.333950    2783 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-29 05:35:14.337769: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import clip\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from dataloaders import CustomDataLoader\n",
    "from custom_tokenizers import Tokenizer\n",
    "from types import SimpleNamespace\n",
    "from decoder_layers import KVCache, PaliGemmaForConditionalGeneration\n",
    "from configs.config import DataConfig, EncoderConfig, DecoderConfig, PaliGemmaConfig\n",
    "from metrics import compute_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54211390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search_generate(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    pixel_values,        # shape: (B, 2, C, H, W)\n",
    "    image_token_index,   # placeholder index for image tokens\n",
    "    max_length=60,\n",
    "    num_beams=5,\n",
    "    eos_token_id=2,\n",
    "    pad_token_id=0,\n",
    "    device=\"cuda\",\n",
    "):\n",
    "    model.eval()\n",
    "    batch_size = pixel_values.size(0)\n",
    "    eos_token_id = eos_token_id or tokenizer.eos_token_id\n",
    "\n",
    "    # Encode images\n",
    "    B, N, C, H, W = pixel_values.shape\n",
    "    pixel_values = pixel_values.view(B * N, C, H, W).to(device)\n",
    "    pixel_values = pixel_values.to(dtype=next(model.vision_tower.parameters()).dtype, device=\"cuda\")\n",
    "    vision_features = model.vision_tower(pixel_values)\n",
    "    vision_features = vision_features.view(B, N, *vision_features.shape[1:])\n",
    "    image_features = torch.cat([vision_features[:, 0], vision_features[:, 1]], dim=1)\n",
    "    image_features = model.multi_modal_projector(image_features)  # shape: [B, Seq, Hidden]\n",
    "\n",
    "    # Init input_ids with image token index\n",
    "    input_ids = torch.full((batch_size * num_beams, 1), image_token_index, dtype=torch.long, device=device)\n",
    "    attention_mask = torch.ones_like(input_ids, device=device)\n",
    "\n",
    "    # Expand inputs for each beam\n",
    "    image_features = image_features.unsqueeze(1).repeat(1, num_beams, 1, 1)\n",
    "    image_features = image_features.view(batch_size * num_beams, *image_features.shape[2:])\n",
    "\n",
    "    beam_scores = torch.zeros((batch_size, num_beams), device=device)\n",
    "    beam_scores[:, 1:] = -1e9  # mask beams other than first\n",
    "    beam_scores = beam_scores.view(-1)  # shape: [B * num_beams]\n",
    "\n",
    "    sequences = input_ids\n",
    "    is_done = [False] * batch_size\n",
    "\n",
    "    for step in range(max_length):\n",
    "        # Embedding\n",
    "        input_embeds = model.language_model.get_input_embeddings()(sequences)\n",
    "        \n",
    "        # Merge image + text features\n",
    "        merged_input, attn_mask, pos_ids = model._merge_input_ids_with_image_features(\n",
    "            input_ids = sequences, image_features = image_features, inputs_embeds = input_embeds, attention_mask = attention_mask, kv_cache=None\n",
    "        )\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model.language_model(\n",
    "            inputs_embeds=merged_input,\n",
    "            attention_mask=attn_mask,\n",
    "            position_ids=pos_ids,\n",
    "        )\n",
    "        logits = outputs[\"logits\"]  # shape: [B * num_beams, Seq_len, Vocab]\n",
    "        next_token_logits = logits[:, -1, :]  # take last token only\n",
    "        next_token_log_probs = F.log_softmax(next_token_logits, dim=-1)\n",
    "        # next_token_log_probs[:, image_token_index] = -1e9\n",
    "\n",
    "\n",
    "        # Add current beam scores\n",
    "        next_token_log_probs = next_token_log_probs + beam_scores[:, None]\n",
    "\n",
    "        # Get top k * num_beams candidates\n",
    "        vocab_size = next_token_log_probs.size(-1)\n",
    "        next_token_log_probs = next_token_log_probs.view(batch_size, num_beams * vocab_size)\n",
    "        topk_log_probs, topk_indices = torch.topk(next_token_log_probs, num_beams, dim=-1)\n",
    "\n",
    "        # Prepare for next step\n",
    "        beam_indices = topk_indices // vocab_size\n",
    "        token_indices = topk_indices % vocab_size\n",
    "\n",
    "        # Reorder sequences and image features\n",
    "        sequences = sequences.view(batch_size, num_beams, -1)\n",
    "        new_sequences = []\n",
    "        for i in range(batch_size):\n",
    "            new_sequences.append(sequences[i, beam_indices[i]])\n",
    "        sequences = torch.stack(new_sequences).view(batch_size * num_beams, -1)\n",
    "        sequences = torch.cat([sequences, token_indices.view(-1, 1)], dim=-1)\n",
    "\n",
    "        # Update scores\n",
    "        beam_scores = topk_log_probs.view(-1)\n",
    "\n",
    "        # Update attention mask\n",
    "        attention_mask = torch.cat([attention_mask, torch.ones_like(token_indices.view(-1, 1))], dim=1)\n",
    "\n",
    "        # Check if all sequences have ended\n",
    "        if eos_token_id is not None:\n",
    "            for i in range(batch_size):\n",
    "                done_for_beam = True\n",
    "                for beam_id in range(num_beams):\n",
    "                    token = sequences[i * num_beams + beam_id, -1]\n",
    "                    if token != eos_token_id:\n",
    "                        done_for_beam = False\n",
    "                        break\n",
    "                is_done[i] = done_for_beam\n",
    "        \n",
    "            if all(is_done):\n",
    "                break\n",
    "\n",
    "    # Reshape to [batch_size, num_beams, seq_len] and pick best beam\n",
    "    sequences = sequences.view(batch_size, num_beams, -1)\n",
    "    beam_scores = beam_scores.view(batch_size, num_beams)\n",
    "    best_indices = torch.argmax(beam_scores, dim=1)\n",
    "\n",
    "    best_sequences = []\n",
    "    for i in range(batch_size):\n",
    "        best_sequences.append(sequences[i, best_indices[i]])\n",
    "    best_sequences = torch.stack(best_sequences)\n",
    "\n",
    "    return best_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8f75798",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for PaliGemmaForConditionalGeneration:\n\tUnexpected key(s) in state_dict: \"language_model.model.ln.weight\", \"language_model.model.ln.bias\". \n\tsize mismatch for multi_modal_projector.linear.weight: copying a param with shape torch.Size([392, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for multi_modal_projector.linear.bias: copying a param with shape torch.Size([392]) from checkpoint, the shape in current model is torch.Size([768]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m config \u001b[38;5;241m=\u001b[39m PaliGemmaConfig(text_config\u001b[38;5;241m=\u001b[39mDecoderConfig(), vision_config\u001b[38;5;241m=\u001b[39mEncoderConfig())\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m PaliGemmaForConditionalGeneration(config)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcheckpoints/experiment_1.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      7\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m Tokenizer(DataConfig())\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:2581\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2573\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2574\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2575\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2576\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[1;32m   2577\u001b[0m             ),\n\u001b[1;32m   2578\u001b[0m         )\n\u001b[1;32m   2580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2581\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2583\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[1;32m   2584\u001b[0m         )\n\u001b[1;32m   2585\u001b[0m     )\n\u001b[1;32m   2586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for PaliGemmaForConditionalGeneration:\n\tUnexpected key(s) in state_dict: \"language_model.model.ln.weight\", \"language_model.model.ln.bias\". \n\tsize mismatch for multi_modal_projector.linear.weight: copying a param with shape torch.Size([392, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for multi_modal_projector.linear.bias: copying a param with shape torch.Size([392]) from checkpoint, the shape in current model is torch.Size([768])."
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "config = PaliGemmaConfig(text_config=DecoderConfig(), vision_config=EncoderConfig())\n",
    "model = PaliGemmaForConditionalGeneration(config)\n",
    "model.load_state_dict(torch.load(\"checkpoints/experiment_1.pt\", map_location=\"cuda\"))\n",
    "model.eval()\n",
    "\n",
    "tokenizer = Tokenizer(DataConfig())\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_clip, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "model = model.to(device)\n",
    "\n",
    "# Load and preprocess image\n",
    "image_1 = preprocess(Image.open(\"data/updated_iu_xray/CXR38_IM-1911/0.png\"))\n",
    "image_2 = preprocess(Image.open(\"data/updated_iu_xray/CXR38_IM-1911/1.png\"))\n",
    "pixel_values = torch.stack((image_1, image_2), 0).unsqueeze(0)\n",
    "generated_ids = beam_search_generate(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    pixel_values=pixel_values,\n",
    "    image_token_index=config.image_token_index,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    device=\"cuda\",\n",
    "    num_beams=5,\n",
    "    max_length=100,\n",
    ")\n",
    "\n",
    "# Decode to text\n",
    "captions = tokenizer.decode_batch(generated_ids)\n",
    "for caption in captions:\n",
    "    print(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12e8fe61-0a2c-4053-9fab-c141c51a74e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, tokenizer, dataloader, device, image_token_index, max_len=60, num_beams=5):\n",
    "    model.eval()\n",
    "    gts = {}\n",
    "    res = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tqdm(dataloader, desc=\"Evaluating\")):\n",
    "            input_ids, pixel_values, att_masks = batch\n",
    "            pixel_values = pixel_values.to(device)\n",
    "\n",
    "            generated_ids = beam_search_generate(\n",
    "                model,\n",
    "                tokenizer,\n",
    "                pixel_values=pixel_values,\n",
    "                image_token_index=image_token_index,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                device=device,\n",
    "                num_beams=num_beams,\n",
    "                max_length=max_len,\n",
    "            )\n",
    "\n",
    "            # Decode predictions\n",
    "            decoded_preds = tokenizer.decode_batch(generated_ids)\n",
    "            decoded_preds = [pred.strip().lower() for pred in decoded_preds]\n",
    "\n",
    "            # Decode references\n",
    "            references = input_ids\n",
    "            if isinstance(references[0], torch.Tensor):\n",
    "                references = [tokenizer.decode(ref).replace(\"<image>\", \"\").strip().lower() for ref in references]\n",
    "\n",
    "            batch_size = pixel_values.size(0)\n",
    "            for j in range(batch_size):\n",
    "                image_id = f\"img_{i * batch_size + j}\"\n",
    "                gts[image_id] = [references[j]]  # list of refs\n",
    "                res[image_id] = [decoded_preds[j]]  # model output\n",
    "            for i in range(1):\n",
    "                print(f\"Pred: {decoded_preds[i]}\")\n",
    "                print(f\"Ref: {references[i]}\")\n",
    "                print()\n",
    "\n",
    "    scores = compute_scores(gts, res)\n",
    "\n",
    "    # Optional print\n",
    "    for metric, score in scores.items():\n",
    "        print(f\"{metric.upper()}: {score:.4f}\")\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b668f14-5ff7-4489-b21c-85a9f9edbc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Java for Meteor\n",
    "# !apt-get update -y\n",
    "# !apt-get install -y openjdk-17-jre-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2609b2d7-6879-4a71-9e45-333fb39dcc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  10%|█         | 1/10 [00:07<01:05,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: <image> the lungs are clear without evidence of the lungs are clear without evidence of the lungs are clear without evidence of the lungs are clear without evidence of the lungs are clear without evidence of the cardiac monitor leads show an unchanged from prior granulomatous process the heart size and vasculature central venous catheter tip overlying external cardiac monitor leads\n",
      "Ref: <bos> the heart size and pulmonary vascularity appear within normal limits . the lungs are free of focal airspace disease . no pleural effusion or pneumothorax is seen . <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  20%|██        | 2/10 [00:13<00:52,  6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: <image> there are clear without acute bony structures show an unchanged from prior examination consists normal limits . there is a small t-spine osteophytes mediastinal contours are clear without acute bony structures show an unchanged from prior examination consists normal limits . <eos>\n",
      "Ref: <bos> lungs are clear . there is no pneumothorax or pleural effusion . the heart and mediastinum are within normal limits . bony structures are intact . <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  30%|███       | 3/10 [00:19<00:44,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: <image> status post limits . <eos>\n",
      "Ref: <bos> the lungs are clear . there is no pleural effusion or pneumothorax . the heart is not significantly enlarged . the mediastinum is normal . arthritic changes of the skeletal structures are noted . <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  40%|████      | 4/10 [00:25<00:37,  6.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: <image> the lungs are clear without evidence of the lungs are clear without evidence of the lungs are clear without evidence of the lungs are clear without evidence of the lungs are clear without evidence of the cardiac monitor leads show an unchanged from prior granulomatous process the heart size and vasculature central venous catheter tip overlying external cardiac monitor leads\n",
      "Ref: <bos> there is persistent marked enlargement of the pulmonary arteries . normal heart size . no focal airspace consolidation . no pleural effusion or pneumothorax . visualized osseous structures are unremarkable in appearance . <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  50%|█████     | 5/10 [00:31<00:31,  6.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: <image> both lungs are clear without acute bony structures show an unchanged from prior examination consists normal limits . there is a small t-spine osteophytes mediastinal contours are clear without acute bony structures show an unchanged from prior examination consists normal limits . <eos>\n",
      "Ref: <bos> the cardiomediastinal silhouette is normal in size and contour . no focal consolidation pneumothorax or large pleural effusion . normal xxxx . <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  60%|██████    | 6/10 [00:38<00:25,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: <image> the lungs are clear without evidence of the lungs are clear without evidence of the lungs are clear without evidence of the lungs are clear without evidence of the lungs are clear without evidence of the cardiac monitor leads show an unchanged from prior granulomatous process the heart size and vasculature central venous catheter tip overlying external cardiac monitor leads\n",
      "Ref: <bos> cardiomediastinal silhouette within normal limits . no acute bony abnormality . there are xxxx xxxx opacities atelectasis versus airspace disease . no large effusion or pneumothorax . <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  70%|███████   | 7/10 [00:44<00:18,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: <image> . <eos>\n",
      "Ref: <bos> the heart size and pulmonary vascularity appear within normal limits . the lungs are free of focal airspace disease . no pleural effusion or pneumothorax is seen . <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  80%|████████  | 8/10 [00:50<00:12,  6.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: <image> . <eos>\n",
      "Ref: <bos> cardiac and mediastinal contours are within normal limits . prior granulomatous disease . the lungs are clear . thoracic spondylosis . <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  90%|█████████ | 9/10 [00:57<00:06,  6.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: <image> result bronchovascular crowding as well aerated suspicious pulmonary vascularity appear within normal limits . there are clear without acute bony structures show an unchanged from prior examination consists normal limits for patient age . <eos>\n",
      "Ref: <bos> lung volumes remain low . no infiltrates . heart and pulmonary xxxx remain normal . <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 10/10 [00:58<00:00,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: <image> are clear without acute bony structures show an unchanged from prior examination consists normal limits . there is a small t-spine osteophytes mediastinal contours are clear without acute bony structures show an unchanged from prior examination consists normal limits . <eos>\n",
      "Ref: <bos> lungs are clear without focal consolidation effusion or pneumothorax . normal heart size . negative for <unk> . mild degenerative changes of the thoracic spine . <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU_1: 0.1270\n",
      "BLEU_2: 0.0820\n",
      "BLEU_3: 0.0470\n",
      "BLEU_4: 0.0268\n",
      "METEOR: 0.1035\n",
      "ROUGE_L: 0.1241\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU_1': 0.1269983373832917,\n",
       " 'BLEU_2': 0.08195098960400135,\n",
       " 'BLEU_3': 0.04700835898767729,\n",
       " 'BLEU_4': 0.02680478528886467,\n",
       " 'METEOR': 0.10346761761716412,\n",
       " 'ROUGE_L': np.float64(0.12414180940742026)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(DataConfig())\n",
    "\n",
    "test_loader = CustomDataLoader(\n",
    "    split=\"test\",\n",
    "    batch_size=64,\n",
    "    num_workers=1,\n",
    "    tokenizer=tokenizer,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "scores = evaluate_model(model, tokenizer, test_loader, device, image_token_index=763)\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
