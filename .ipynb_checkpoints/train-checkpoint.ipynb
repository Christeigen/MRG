{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53852407",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62b056cc-60b0-4f48-92f2-7e717fa0f026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eff8bae3-fede-445e-9150-ab7aa0fa1f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt-get update -y\n",
    "# !apt-get install -y openjdk-17-jre-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "754e3a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-03 06:19:53.310670: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-03 06:19:53.321143: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751523593.334046    2631 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751523593.338048    2631 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1751523593.348615    2631 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751523593.348635    2631 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751523593.348637    2631 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751523593.348638    2631 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-03 06:19:53.352218: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "from transformers import get_scheduler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from custom_tokenizers import Tokenizer\n",
    "from configs.config import DataConfig, EncoderConfig, DecoderConfig, PaliGemmaConfig\n",
    "from decoder_layers import KVCache, PaliGemmaForConditionalGeneration\n",
    "from dataloaders import CustomDataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf9671bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model,\n",
    "    dataloader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    epoch,\n",
    "    grad_accumulation_steps=1,\n",
    "    max_grad_norm=1.0,\n",
    "    use_amp=False,\n",
    "):\n",
    "    model.train()\n",
    "    kv_cache = KVCache()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "    config = DecoderConfig()\n",
    "\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for step, batch in enumerate(tqdm(dataloader, desc=f\"Epoch {epoch}\")):\n",
    "        input_ids, pixel_values, attention_mask = batch\n",
    "        input_ids = input_ids.to(device)\n",
    "        pixel_values = pixel_values.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        with torch.cuda.amp.autocast(enabled=use_amp):\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                pixel_values=pixel_values,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            \n",
    "            logits = outputs[\"logits\"]\n",
    "            shift_logits = logits[:, :-1, :].contiguous()\n",
    "            shift_labels = input_ids[:, 1:].contiguous()\n",
    "            \n",
    "            loss = torch.nn.functional.cross_entropy(\n",
    "                shift_logits.view(-1, config.vocab_size),\n",
    "                shift_labels.view(-1),\n",
    "                label_smoothing=0.1\n",
    "            )\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (step + 1) % grad_accumulation_steps == 0:\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, dataloader, device, use_amp=False):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "    config = DecoderConfig()\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=\"Validating\"):\n",
    "        input_ids, pixel_values, attention_mask = batch\n",
    "        input_ids = input_ids.to(device)\n",
    "        pixel_values = pixel_values.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=use_amp):\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                pixel_values=pixel_values,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            logits = outputs[\"logits\"]  # shape: [B, T, V]\n",
    "            shift_logits = logits[:, :-1, :].contiguous()\n",
    "            shift_labels = input_ids[:, 1:].contiguous()\n",
    "            \n",
    "            loss = torch.nn.functional.cross_entropy(\n",
    "                shift_logits.view(-1, config.vocab_size),\n",
    "                shift_labels.view(-1),\n",
    "                label_smoothing=0.1\n",
    "            )\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58d00b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Hyperparameters\n",
    "    epochs = 10\n",
    "    batch_size = 64\n",
    "    learning_rate = 3e-5\n",
    "    grad_accumulation_steps = 1\n",
    "    use_amp = True\n",
    "    patience = 30\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    # === Load Config ===\n",
    "    text_config = DecoderConfig()\n",
    "    vision_config = EncoderConfig()\n",
    "    text_config.vocab_size += 1\n",
    "    image_token_index = text_config.vocab_size - 1\n",
    "    config = PaliGemmaConfig(\n",
    "        text_config=text_config,\n",
    "        vision_config=vision_config,\n",
    "        image_token_index=image_token_index,\n",
    "    )\n",
    "\n",
    "    # === Load Model ===\n",
    "    model = PaliGemmaForConditionalGeneration(config).to(device)\n",
    "\n",
    "    # Tokenizer\n",
    "    tokenizer = Tokenizer(DataConfig())\n",
    "\n",
    "    # === Dataloader ===\n",
    "    train_loader = CustomDataLoader(\n",
    "        split=\"train\",\n",
    "        batch_size=batch_size,\n",
    "        num_workers=1,\n",
    "        tokenizer=tokenizer,\n",
    "        shuffle=True\n",
    "    )\n",
    "    val_loader = CustomDataLoader(\n",
    "        split=\"val\",\n",
    "        batch_size=batch_size,\n",
    "        num_workers=1,\n",
    "        tokenizer=tokenizer,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # === Optimizer and Scheduler ===\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "    num_training_steps = epochs * len(train_loader) // grad_accumulation_steps\n",
    "    # lr_scheduler = get_scheduler(\n",
    "    #     \"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    "    # )\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, threshold=0.0001, threshold_mode='abs')\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "\n",
    "    # === Training Loop ===\n",
    "    start_time = time.time()\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        avg_train_loss = train(\n",
    "            model,\n",
    "            train_loader,\n",
    "            optimizer,\n",
    "            # lr_scheduler,\n",
    "            device,\n",
    "            epoch,\n",
    "            grad_accumulation_steps,\n",
    "            use_amp=use_amp,\n",
    "        )\n",
    "        avg_val_loss = validate(model, val_loader, device, use_amp)\n",
    "        lr_scheduler.step(avg_val_loss)\n",
    "        train_loss.append(avg_train_loss)\n",
    "        val_loss.append(avg_val_loss)\n",
    "        print(f\"Epoch {epoch} - Train Loss: {avg_train_loss:.4f} - Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            print(\"Validation loss improved. Saving model...\")\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "            torch.save(model.state_dict(), f\"checkpoints/experiment_6.pt\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"No improvement. Patience: {patience_counter}/{patience}\")\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "    save_dir = \"plot\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Plotting\n",
    "    epochs = list(range(1, len(train_loss) + 1))\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(epochs, train_loss, label='Train Loss', marker='o')\n",
    "    plt.plot(epochs, val_loss, label='Validation Loss', marker='x')\n",
    "    plt.title(\"Training and Validation Loss per Epoch\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Save the plot\n",
    "    plot_path = os.path.join(save_dir, \"experiment_6.png\")\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()\n",
    "\n",
    "    # Calculate elapsed time\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Elapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a817e6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 33/33 [00:35<00:00,  1.06s/it]\n",
      "Validating: 100%|██████████| 5/5 [00:05<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Train Loss: 3.8154 - Val Loss: 2.3447\n",
      "Validation loss improved. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 33/33 [00:34<00:00,  1.04s/it]\n",
      "Validating: 100%|██████████| 5/5 [00:05<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Train Loss: 2.0775 - Val Loss: 1.9575\n",
      "Validation loss improved. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 33/33 [00:34<00:00,  1.05s/it]\n",
      "Validating: 100%|██████████| 5/5 [00:05<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Train Loss: 1.8767 - Val Loss: 1.7503\n",
      "Validation loss improved. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 33/33 [00:34<00:00,  1.05s/it]\n",
      "Validating: 100%|██████████| 5/5 [00:05<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Train Loss: 1.6936 - Val Loss: 1.6201\n",
      "Validation loss improved. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 33/33 [00:34<00:00,  1.05s/it]\n",
      "Validating: 100%|██████████| 5/5 [00:05<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Train Loss: 1.5928 - Val Loss: 1.5533\n",
      "Validation loss improved. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 33/33 [00:34<00:00,  1.03s/it]\n",
      "Validating: 100%|██████████| 5/5 [00:05<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Train Loss: 1.5428 - Val Loss: 1.5148\n",
      "Validation loss improved. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 33/33 [00:34<00:00,  1.04s/it]\n",
      "Validating: 100%|██████████| 5/5 [00:05<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Train Loss: 1.5102 - Val Loss: 1.4876\n",
      "Validation loss improved. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 33/33 [00:34<00:00,  1.04s/it]\n",
      "Validating: 100%|██████████| 5/5 [00:05<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Train Loss: 1.4866 - Val Loss: 1.4668\n",
      "Validation loss improved. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 33/33 [00:34<00:00,  1.04s/it]\n",
      "Validating: 100%|██████████| 5/5 [00:05<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Train Loss: 1.4655 - Val Loss: 1.4497\n",
      "Validation loss improved. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 33/33 [00:33<00:00,  1.02s/it]\n",
      "Validating: 100%|██████████| 5/5 [00:05<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Train Loss: 1.4489 - Val Loss: 1.4359\n",
      "Validation loss improved. Saving model...\n",
      "Elapsed time: 416.77386713027954 seconds\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87a85d1d-bcc9-4093-901b-02f080ddc7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import clip\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from dataloaders import CustomDataLoader\n",
    "from custom_tokenizers import Tokenizer\n",
    "from types import SimpleNamespace\n",
    "from decoder_layers import KVCache, PaliGemmaForConditionalGeneration\n",
    "from configs.config import DataConfig, EncoderConfig, DecoderConfig, PaliGemmaConfig\n",
    "from metrics import compute_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "730b2268-52b6-4b00-a221-e13c9a67cc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def greedy_generate(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    pixel_values,        # shape: (B, 2, C, H, W)\n",
    "    image_token_index,   # placeholder index for image tokens\n",
    "    max_length=60,\n",
    "    eos_token_id=2,\n",
    "    pad_token_id=0,\n",
    "    device=\"cuda\",\n",
    "):\n",
    "    model.eval()\n",
    "    batch_size = pixel_values.size(0)\n",
    "    eos_token_id = eos_token_id or tokenizer.eos_token_id\n",
    "\n",
    "    # Encode images\n",
    "    B, N, C, H, W = pixel_values.shape\n",
    "    pixel_values = pixel_values.view(B * N, C, H, W).to(device)\n",
    "    pixel_values = pixel_values.to(dtype=next(model.vision_tower.parameters()).dtype, device=device)\n",
    "    vision_features = model.vision_tower(pixel_values)\n",
    "    vision_features = vision_features.view(B, N, *vision_features.shape[1:])\n",
    "    image_features = torch.cat([vision_features[:, 0], vision_features[:, 1]], dim=1)\n",
    "    image_features = model.multi_modal_projector(image_features)  # shape: [B, Seq, Hidden]\n",
    "\n",
    "    # Initialize sequence\n",
    "    input_ids = torch.full((batch_size, 1), image_token_index, dtype=torch.long, device=device)\n",
    "    attention_mask = torch.ones_like(input_ids)\n",
    "\n",
    "    # Initialize done mask\n",
    "    is_done = torch.zeros(batch_size, dtype=torch.bool, device=device)\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        # Embedding\n",
    "        input_embeds = model.language_model.get_input_embeddings()(input_ids)\n",
    "\n",
    "        # Merge image and text\n",
    "        merged_input, attn_mask, pos_ids = model._merge_input_ids_with_image_features(\n",
    "            input_ids=input_ids,\n",
    "            image_features=image_features,\n",
    "            inputs_embeds=input_embeds,\n",
    "            attention_mask=attention_mask,\n",
    "            kv_cache=None\n",
    "        )\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model.language_model(\n",
    "            inputs_embeds=merged_input,\n",
    "            attention_mask=attn_mask,\n",
    "            position_ids=pos_ids,\n",
    "        )\n",
    "\n",
    "        logits = outputs[\"logits\"]\n",
    "        next_token_logits = logits[:, -1, :]  # Last token logits\n",
    "        next_token = torch.argmax(next_token_logits, dim=-1).unsqueeze(1)  # Greedy pick\n",
    "\n",
    "        input_ids = torch.cat([input_ids, next_token], dim=1)\n",
    "        attention_mask = torch.cat([attention_mask, torch.ones_like(next_token)], dim=1)\n",
    "\n",
    "        # Mark sequences that have ended\n",
    "        is_done = is_done | (next_token.squeeze(1) == eos_token_id)\n",
    "        if is_done.all():\n",
    "            break\n",
    "\n",
    "    return input_ids\n",
    "\n",
    "def beam_search_generate(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    pixel_values,        # shape: (B, 2, C, H, W)\n",
    "    image_token_index,   # placeholder index for image tokens\n",
    "    max_length=60,\n",
    "    num_beams=5,\n",
    "    eos_token_id=2,\n",
    "    pad_token_id=0,\n",
    "    device=\"cuda\",\n",
    "):\n",
    "    model.eval()\n",
    "    batch_size = pixel_values.size(0)\n",
    "    eos_token_id = eos_token_id or tokenizer.eos_token_id\n",
    "\n",
    "    # Encode images\n",
    "    B, N, C, H, W = pixel_values.shape\n",
    "    pixel_values = pixel_values.view(B * N, C, H, W).to(device)\n",
    "    pixel_values = pixel_values.to(dtype=next(model.vision_tower.parameters()).dtype, device=\"cuda\")\n",
    "    vision_features = model.vision_tower(pixel_values)\n",
    "    vision_features = vision_features.view(B, N, *vision_features.shape[1:])\n",
    "    image_features = torch.cat([vision_features[:, 0], vision_features[:, 1]], dim=1)\n",
    "    image_features = model.multi_modal_projector(image_features)  # shape: [B, Seq, Hidden]\n",
    "\n",
    "    # Init input_ids with image token index\n",
    "    input_ids = torch.full((batch_size * num_beams, 1), image_token_index, dtype=torch.long, device=device)\n",
    "    attention_mask = torch.ones_like(input_ids, device=device)\n",
    "\n",
    "    # Expand inputs for each beam\n",
    "    image_features = image_features.unsqueeze(1).repeat(1, num_beams, 1, 1)\n",
    "    image_features = image_features.view(batch_size * num_beams, *image_features.shape[2:])\n",
    "\n",
    "    beam_scores = torch.zeros((batch_size, num_beams), device=device)\n",
    "    beam_scores[:, 1:] = -1e9  # mask beams other than first\n",
    "    beam_scores = beam_scores.view(-1)  # shape: [B * num_beams]\n",
    "\n",
    "    sequences = input_ids\n",
    "    is_done = [False] * batch_size\n",
    "\n",
    "    for step in range(max_length):\n",
    "        # Embedding\n",
    "        input_embeds = model.language_model.get_input_embeddings()(sequences)\n",
    "        \n",
    "        # Merge image + text features\n",
    "        merged_input, attn_mask, pos_ids = model._merge_input_ids_with_image_features(\n",
    "            input_ids = sequences, image_features = image_features, inputs_embeds = input_embeds, attention_mask = attention_mask, kv_cache=None\n",
    "        )\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model.language_model(\n",
    "            inputs_embeds=merged_input,\n",
    "            attention_mask=attn_mask,\n",
    "            position_ids=pos_ids,\n",
    "        )\n",
    "        logits = outputs[\"logits\"]  # shape: [B * num_beams, Seq_len, Vocab]\n",
    "        next_token_logits = logits[:, -1, :]  # take last token only\n",
    "        next_token_log_probs = F.log_softmax(next_token_logits, dim=-1)\n",
    "        # next_token_log_probs[:, image_token_index] = -1e9\n",
    "\n",
    "\n",
    "        # Add current beam scores\n",
    "        next_token_log_probs = next_token_log_probs + beam_scores[:, None]\n",
    "\n",
    "        # Get top k * num_beams candidates\n",
    "        vocab_size = next_token_log_probs.size(-1)\n",
    "        next_token_log_probs = next_token_log_probs.view(batch_size, num_beams * vocab_size)\n",
    "        topk_log_probs, topk_indices = torch.topk(next_token_log_probs, num_beams, dim=-1)\n",
    "\n",
    "        # Prepare for next step\n",
    "        beam_indices = topk_indices // vocab_size\n",
    "        token_indices = topk_indices % vocab_size\n",
    "\n",
    "        # Reorder sequences and image features\n",
    "        sequences = sequences.view(batch_size, num_beams, -1)\n",
    "        new_sequences = []\n",
    "        for i in range(batch_size):\n",
    "            new_sequences.append(sequences[i, beam_indices[i]])\n",
    "        sequences = torch.stack(new_sequences).view(batch_size * num_beams, -1)\n",
    "        sequences = torch.cat([sequences, token_indices.view(-1, 1)], dim=-1)\n",
    "\n",
    "        # Update scores\n",
    "        beam_scores = topk_log_probs.view(-1)\n",
    "\n",
    "        # Update attention mask\n",
    "        attention_mask = torch.cat([attention_mask, torch.ones_like(token_indices.view(-1, 1))], dim=1)\n",
    "\n",
    "        # Check if all sequences have ended\n",
    "        if eos_token_id is not None:\n",
    "            for i in range(batch_size):\n",
    "                done_for_beam = True\n",
    "                for beam_id in range(num_beams):\n",
    "                    token = sequences[i * num_beams + beam_id, -1]\n",
    "                    if token != eos_token_id:\n",
    "                        done_for_beam = False\n",
    "                        break\n",
    "                is_done[i] = done_for_beam\n",
    "        \n",
    "            if all(is_done):\n",
    "                break\n",
    "\n",
    "    # Reshape to [batch_size, num_beams, seq_len] and pick best beam\n",
    "    sequences = sequences.view(batch_size, num_beams, -1)\n",
    "    beam_scores = beam_scores.view(batch_size, num_beams)\n",
    "    best_indices = torch.argmax(beam_scores, dim=1)\n",
    "\n",
    "    best_sequences = []\n",
    "    for i in range(batch_size):\n",
    "        best_sequences.append(sequences[i, best_indices[i]])\n",
    "    best_sequences = torch.stack(best_sequences)\n",
    "\n",
    "    return best_sequences\n",
    "\n",
    "\n",
    "def evaluate_model(model, tokenizer, dataloader, device, image_token_index, decoding, max_len=60, num_beams=5):\n",
    "    model.eval()\n",
    "    gts = {}\n",
    "    res = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tqdm(dataloader, desc=\"Evaluating\")):\n",
    "            input_ids, pixel_values, att_masks = batch\n",
    "            pixel_values = pixel_values.to(device)\n",
    "\n",
    "            if decoding == \"greedy\":\n",
    "                print(\"generate with greedy\")\n",
    "                generated_ids = greedy_generate(\n",
    "                    model,\n",
    "                    tokenizer,\n",
    "                    pixel_values=pixel_values,\n",
    "                    image_token_index=image_token_index,\n",
    "                    eos_token_id=tokenizer.eos_token_id,\n",
    "                    device=device,\n",
    "                    max_length=max_len,\n",
    "                )\n",
    "            else:\n",
    "                print(\"generate with beam\")\n",
    "                generated_ids = beam_search_generate(\n",
    "                    model,\n",
    "                    tokenizer,\n",
    "                    pixel_values=pixel_values,\n",
    "                    image_token_index=image_token_index,\n",
    "                    eos_token_id=tokenizer.eos_token_id,\n",
    "                    device=device,\n",
    "                    num_beams=num_beams,\n",
    "                    max_length=max_len,\n",
    "                )\n",
    "\n",
    "            # Decode predictions\n",
    "            decoded_preds = tokenizer.decode_batch(generated_ids)\n",
    "            decoded_preds = [pred.strip().lower() for pred in decoded_preds]\n",
    "\n",
    "            # Decode references\n",
    "            references = input_ids\n",
    "            if isinstance(references[0], torch.Tensor):\n",
    "                references = [tokenizer.decode(ref).replace(\"<image>\", \"\").strip().lower() for ref in references]\n",
    "\n",
    "            batch_size = pixel_values.size(0)\n",
    "            for j in range(batch_size):\n",
    "                image_id = f\"img_{i * batch_size + j}\"\n",
    "                gts[image_id] = [references[j]]  # list of refs\n",
    "                res[image_id] = [decoded_preds[j]]  # model output\n",
    "            for i in range(1):\n",
    "                print(f\"Pred: {decoded_preds[i]}\")\n",
    "                print(f\"Ref: {references[i]}\")\n",
    "                print()\n",
    "\n",
    "    scores = compute_scores(gts, res)\n",
    "\n",
    "    # Optional print\n",
    "    for metric, score in scores.items():\n",
    "        print(f\"{metric.upper()}: {score:.4f}\")\n",
    "\n",
    "    return scores, gts, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55193c40-a4d9-41e5-b753-0fcc98af0f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 338M/338M [00:02<00:00, 167MiB/s]\n",
      "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate with greedy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  10%|█         | 1/10 [00:03<00:28,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: <image> 5th acute bony structures reveal masses replacement exam most compatible with tip projects over the cardiac silhouette is a small t-spine osteophytes changes throughout both lungs are clear bilaterally more this could represent sequelae <bos> frontal view reveals granulomas throughout both lungs are clear bilaterally more this could represent sequelae <bos> frontal view reveals granulomas throughout both lungs are clear\n",
      "Ref: <bos> unchanged cardiomegaly . there is <unk> interstitial prominence bilaterally . unchanged vascular appearance . there is patchy retrocardiac opacity . negative for pneumothorax . <eos>\n",
      "\n",
      "generate with greedy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  20%|██        | 2/10 [00:04<00:16,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: <image> normally inflated without evidence of frontal view reveals granulomas throughout both lungs are clear bilaterally more this could represent sequelae <bos> frontal view reveals granulomas throughout both lungs are clear bilaterally more this could represent sequelae <bos> frontal view reveals granulomas throughout both lungs are clear bilaterally more this could represent sequelae <bos> frontal view reveals granulomas throughout both lungs\n",
      "Ref: <bos> the cardiomediastinal silhouette is within normal limits . there is rounded calcified density within the left lower lobe most consistent with granuloma . <unk> lungs are clear without evidence of focal opacification . no pneumothorax or large pleural effusion . no acute bone abnormality . <eos>\n",
      "\n",
      "generate with greedy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  30%|███       | 3/10 [00:05<00:12,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: <image> normally inflated without evidence of frontal view reveals granulomas throughout both lungs are clear bilaterally more this could represent sequelae <bos> frontal view reveals granulomas throughout both lungs are clear bilaterally more this could represent sequelae <bos> frontal view reveals granulomas throughout both lungs are clear bilaterally more this could represent sequelae <bos> frontal view reveals granulomas throughout both lungs\n",
      "Ref: <bos> no focal lung consolidation . heart size and pulmonary vascularity are within normal limits . no pneumothorax or pleural effusion . osseous structures are grossly intact . <eos>\n",
      "\n",
      "generate with greedy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  40%|████      | 4/10 [00:07<00:09,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: <image> normally inflated without evidence of frontal view reveals granulomas throughout both lungs are clear bilaterally more this could represent sequelae <bos> frontal view reveals granulomas throughout both lungs are clear bilaterally more this could represent sequelae <bos> frontal view reveals granulomas throughout both lungs are clear bilaterally more this could represent sequelae <bos> frontal view reveals granulomas throughout both lungs\n",
      "Ref: <bos> cardiac and mediastinal contours are within normal limits . the lungs are clear . bony structures are intact . <eos>\n",
      "\n",
      "generate with greedy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  50%|█████     | 5/10 [00:08<00:07,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: <image> normally inflated without evidence of frontal view reveals granulomas throughout both lungs are clear bilaterally more images apices could represent sequelae <bos> frontal view reveals granulomas throughout both lungs are clear bilaterally more this could represent sequelae <bos> frontal view reveals granulomas throughout both lungs are clear bilaterally more this could represent sequelae <bos> frontal view reveals granulomas throughout both\n",
      "Ref: <bos> heart size is normal . there are xxxx opacities which appear to xxxx xxxx above the right xxxx fissure . there is mild thickening in the fissure . no pneumothorax . no large pleural effusions . <eos>\n",
      "\n",
      "generate with greedy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  60%|██████    | 6/10 [00:09<00:05,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: <image> normally inflated without evidence of frontal view reveals granulomas throughout both lungs are clear bilaterally more this could represent sequelae <bos> frontal view reveals granulomas throughout both lungs are clear bilaterally more this could represent sequelae <bos> frontal view reveals granulomas throughout both lungs are clear bilaterally more this could represent sequelae <bos> frontal view reveals granulomas throughout both lungs\n",
      "Ref: <bos> mediastinal contours are normal . lungs are clear . there is no pneumothorax or large pleural effusion . <eos>\n",
      "\n",
      "generate with greedy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  70%|███████   | 7/10 [00:11<00:04,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: <image> normally inflated without evidence of frontal view reveals granulomas throughout both lungs are clear bilaterally more this could represent sequelae <bos> frontal view reveals granulomas throughout both lungs are clear bilaterally more this could represent sequelae <bos> frontal view reveals granulomas throughout both lungs are clear bilaterally more this could represent sequelae <bos> frontal view reveals granulomas throughout both lungs\n",
      "Ref: <bos> the heart is normal in size . the mediastinum is unremarkable . the lungs are clear . <eos>\n",
      "\n",
      "generate with greedy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  80%|████████  | 8/10 [00:12<00:02,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: <image> normally inflated without evidence of frontal view reveals granulomas throughout both lungs are clear bilaterally more this could represent sequelae <bos> frontal view reveals granulomas throughout both lungs are clear bilaterally more this could represent sequelae <bos> frontal view reveals granulomas throughout both lungs are clear bilaterally more this could represent sequelae <bos> frontal view reveals granulomas throughout both lungs\n",
      "Ref: <bos> the cardiac contours are normal . the lungs are clear . thoracic spondylosis . <eos>\n",
      "\n",
      "generate with greedy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  90%|█████████ | 9/10 [00:13<00:01,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: <image> normally inflated without evidence of frontal view reveals granulomas throughout both lungs are clear bilaterally more this could represent sequelae <bos> frontal view reveals granulomas throughout both lungs are clear bilaterally more this could represent sequelae <bos> frontal view reveals granulomas throughout both lungs are clear bilaterally more this could represent sequelae <bos> frontal view reveals granulomas throughout both lungs\n",
      "Ref: <bos> the heart pulmonary xxxx and mediastinum are within normal limits . there is no pleural effusion or pneumothorax . there is no focal air space opacity to suggest a pneumonia . <eos>\n",
      "\n",
      "generate with greedy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 10/10 [00:14<00:00,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: <image> <unk> cm nodular density projected over the cardiac silhouette is a small t-spine osteophytes changes throughout both lungs are clear bilaterally more this could represent sequelae <bos> frontal view reveals granulomas throughout both lungs are clear bilaterally more this could represent sequelae <bos> frontal view reveals granulomas throughout both lungs are clear bilaterally more images apices could represent sequelae <bos>\n",
      "Ref: <bos> normal heart size and mediastinal contours . stable calcification in the left upper lobe xxxx representing a granuloma . no focal airspace opacities . no pleural effusion or pneumothorax . visualized osseous structures are unremarkable in appearance . <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU_1: 0.0719\n",
      "BLEU_2: 0.0388\n",
      "BLEU_3: 0.0240\n",
      "BLEU_4: 0.0132\n",
      "METEOR: 0.1057\n",
      "ROUGE_L: 0.0840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU_1': 0.0718856078584496,\n",
       " 'BLEU_2': 0.03876937847659147,\n",
       " 'BLEU_3': 0.024038623641290346,\n",
       " 'BLEU_4': 0.013248570457362201,\n",
       " 'METEOR': 0.1057116640117974,\n",
       " 'ROUGE_L': np.float64(0.08402614183632913)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = PaliGemmaConfig(text_config=DecoderConfig(), vision_config=EncoderConfig())\n",
    "model = PaliGemmaForConditionalGeneration(config)\n",
    "model.load_state_dict(torch.load(\"checkpoints/experiment_2.pt\", map_location=\"cuda\"))\n",
    "model.eval()\n",
    "\n",
    "tokenizer = Tokenizer(DataConfig())\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_clip, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "model = model.to(device)\n",
    "\n",
    "tokenizer = Tokenizer(DataConfig())\n",
    "\n",
    "test_loader = CustomDataLoader(\n",
    "    split=\"test\",\n",
    "    batch_size=64,\n",
    "    num_workers=1,\n",
    "    tokenizer=tokenizer,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "scores, gts, res = evaluate_model(model, tokenizer, test_loader, device, image_token_index=763, decoding=\"greedy\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a7de3af-4c8e-4880-a14f-2a466ea3bdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"gts_greed.json\", \"w\") as file:\n",
    "    json.dump(gts, file)\n",
    "with open(\"res_greed.json\", \"w\") as file:\n",
    "    json.dump(res, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
