{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d77e911",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 05:59:35.642072: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-29 05:59:35.655617: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751176775.668517     689 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751176775.672310     689 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1751176775.683005     689 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751176775.683019     689 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751176775.683021     689 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751176775.683023     689 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-29 05:59:35.687154: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import clip\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from dataloaders import CustomDataLoader\n",
    "from custom_tokenizers import Tokenizer\n",
    "from types import SimpleNamespace\n",
    "from decoder_layers import KVCache, PaliGemmaForConditionalGeneration\n",
    "from configs.config import DataConfig, EncoderConfig, DecoderConfig, PaliGemmaConfig\n",
    "from metrics import compute_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54211390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search_generate(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    pixel_values,        # shape: (B, 2, C, H, W)\n",
    "    image_token_index,   # placeholder index for image tokens\n",
    "    max_length=60,\n",
    "    num_beams=5,\n",
    "    eos_token_id=2,\n",
    "    pad_token_id=0,\n",
    "    device=\"cuda\",\n",
    "):\n",
    "    model.eval()\n",
    "    batch_size = pixel_values.size(0)\n",
    "    eos_token_id = eos_token_id or tokenizer.eos_token_id\n",
    "\n",
    "    # Encode images\n",
    "    B, N, C, H, W = pixel_values.shape\n",
    "    pixel_values = pixel_values.view(B * N, C, H, W).to(device)\n",
    "    pixel_values = pixel_values.to(dtype=next(model.vision_tower.parameters()).dtype, device=\"cuda\")\n",
    "    vision_features = model.vision_tower(pixel_values)\n",
    "    vision_features = vision_features.view(B, N, *vision_features.shape[1:])\n",
    "    image_features = torch.cat([vision_features[:, 0], vision_features[:, 1]], dim=1)\n",
    "    image_features = model.multi_modal_projector(image_features)  # shape: [B, Seq, Hidden]\n",
    "\n",
    "    # Init input_ids with image token index\n",
    "    input_ids = torch.full((batch_size * num_beams, 1), image_token_index, dtype=torch.long, device=device)\n",
    "    attention_mask = torch.ones_like(input_ids, device=device)\n",
    "\n",
    "    # Expand inputs for each beam\n",
    "    image_features = image_features.unsqueeze(1).repeat(1, num_beams, 1, 1)\n",
    "    image_features = image_features.view(batch_size * num_beams, *image_features.shape[2:])\n",
    "\n",
    "    beam_scores = torch.zeros((batch_size, num_beams), device=device)\n",
    "    beam_scores[:, 1:] = -1e9  # mask beams other than first\n",
    "    beam_scores = beam_scores.view(-1)  # shape: [B * num_beams]\n",
    "\n",
    "    sequences = input_ids\n",
    "    is_done = [False] * batch_size\n",
    "\n",
    "    for step in range(max_length):\n",
    "        # Embedding\n",
    "        input_embeds = model.language_model.get_input_embeddings()(sequences)\n",
    "        \n",
    "        # Merge image + text features\n",
    "        merged_input, attn_mask, pos_ids = model._merge_input_ids_with_image_features(\n",
    "            input_ids = sequences, image_features = image_features, inputs_embeds = input_embeds, attention_mask = attention_mask, kv_cache=None\n",
    "        )\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model.language_model(\n",
    "            inputs_embeds=merged_input,\n",
    "            attention_mask=attn_mask,\n",
    "            position_ids=pos_ids,\n",
    "        )\n",
    "        logits = outputs[\"logits\"]  # shape: [B * num_beams, Seq_len, Vocab]\n",
    "        next_token_logits = logits[:, -1, :]  # take last token only\n",
    "        next_token_log_probs = F.log_softmax(next_token_logits, dim=-1)\n",
    "        # next_token_log_probs[:, image_token_index] = -1e9\n",
    "\n",
    "\n",
    "        # Add current beam scores\n",
    "        next_token_log_probs = next_token_log_probs + beam_scores[:, None]\n",
    "\n",
    "        # Get top k * num_beams candidates\n",
    "        vocab_size = next_token_log_probs.size(-1)\n",
    "        next_token_log_probs = next_token_log_probs.view(batch_size, num_beams * vocab_size)\n",
    "        topk_log_probs, topk_indices = torch.topk(next_token_log_probs, num_beams, dim=-1)\n",
    "\n",
    "        # Prepare for next step\n",
    "        beam_indices = topk_indices // vocab_size\n",
    "        token_indices = topk_indices % vocab_size\n",
    "\n",
    "        # Reorder sequences and image features\n",
    "        sequences = sequences.view(batch_size, num_beams, -1)\n",
    "        new_sequences = []\n",
    "        for i in range(batch_size):\n",
    "            new_sequences.append(sequences[i, beam_indices[i]])\n",
    "        sequences = torch.stack(new_sequences).view(batch_size * num_beams, -1)\n",
    "        sequences = torch.cat([sequences, token_indices.view(-1, 1)], dim=-1)\n",
    "\n",
    "        # Update scores\n",
    "        beam_scores = topk_log_probs.view(-1)\n",
    "\n",
    "        # Update attention mask\n",
    "        attention_mask = torch.cat([attention_mask, torch.ones_like(token_indices.view(-1, 1))], dim=1)\n",
    "\n",
    "        # Check if all sequences have ended\n",
    "        if eos_token_id is not None:\n",
    "            for i in range(batch_size):\n",
    "                done_for_beam = True\n",
    "                for beam_id in range(num_beams):\n",
    "                    token = sequences[i * num_beams + beam_id, -1]\n",
    "                    if token != eos_token_id:\n",
    "                        done_for_beam = False\n",
    "                        break\n",
    "                is_done[i] = done_for_beam\n",
    "        \n",
    "            if all(is_done):\n",
    "                break\n",
    "\n",
    "    # Reshape to [batch_size, num_beams, seq_len] and pick best beam\n",
    "    sequences = sequences.view(batch_size, num_beams, -1)\n",
    "    beam_scores = beam_scores.view(batch_size, num_beams)\n",
    "    best_indices = torch.argmax(beam_scores, dim=1)\n",
    "\n",
    "    best_sequences = []\n",
    "    for i in range(batch_size):\n",
    "        best_sequences.append(sequences[i, best_indices[i]])\n",
    "    best_sequences = torch.stack(best_sequences)\n",
    "\n",
    "    return best_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8f75798",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 47.50 GiB of which 10.56 MiB is free. Process 1687999 has 14.44 GiB memory in use. Process 1681600 has 33.04 GiB memory in use. Of the allocated memory 31.83 GiB is allocated by PyTorch, and 731.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m config \u001b[38;5;241m=\u001b[39m PaliGemmaConfig(text_config\u001b[38;5;241m=\u001b[39mDecoderConfig(), vision_config\u001b[38;5;241m=\u001b[39mEncoderConfig())\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mPaliGemmaForConditionalGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoints/experiment_1.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m, map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m/workspace/Code/MRG/decoder_layers.py:380\u001b[0m, in \u001b[0;36mPaliGemmaForConditionalGeneration.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m--> 380\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvision_tower \u001b[38;5;241m=\u001b[39m \u001b[43mCLIPWithLoRA\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvision_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_modal_projector \u001b[38;5;241m=\u001b[39m PaliGemmaMultiModalProjector(config)\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_size \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mvocab_size\n",
      "File \u001b[0;32m/workspace/Code/MRG/encoder_layer.py:25\u001b[0m, in \u001b[0;36mCLIPWithLoRA.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Load CLIP model and preprocess\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess \u001b[38;5;241m=\u001b[39m \u001b[43mclip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip_model_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_model\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Inject LoRA into target modules\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/clip/clip.py:139\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, device, jit, download_root)\u001b[0m\n\u001b[1;32m    136\u001b[0m         state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(opened_file, map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m jit:\n\u001b[0;32m--> 139\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(device) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    141\u001b[0m         model\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1343\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1340\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1341\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1343\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:903\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 903\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    907\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    908\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    914\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:903\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 903\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    907\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    908\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    914\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 903 (3 times)]\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:903\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 903\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    907\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    908\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    914\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:930\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 930\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    931\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    933\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1329\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1323\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1324\u001b[0m             device,\n\u001b[1;32m   1325\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1326\u001b[0m             non_blocking,\n\u001b[1;32m   1327\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1328\u001b[0m         )\n\u001b[0;32m-> 1329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1333\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1334\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1335\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 47.50 GiB of which 10.56 MiB is free. Process 1687999 has 14.44 GiB memory in use. Process 1681600 has 33.04 GiB memory in use. Of the allocated memory 31.83 GiB is allocated by PyTorch, and 731.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "config = PaliGemmaConfig(text_config=DecoderConfig(), vision_config=EncoderConfig())\n",
    "model = PaliGemmaForConditionalGeneration(config)\n",
    "model.load_state_dict(torch.load(\"checkpoints/experiment_1.pt\", map_location=\"cuda\"))\n",
    "model.eval()\n",
    "\n",
    "tokenizer = Tokenizer(DataConfig())\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_clip, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "model = model.to(device)\n",
    "\n",
    "# Load and preprocess image\n",
    "image_1 = preprocess(Image.open(\"data/updated_iu_xray/CXR38_IM-1911/0.png\"))\n",
    "image_2 = preprocess(Image.open(\"data/updated_iu_xray/CXR38_IM-1911/1.png\"))\n",
    "pixel_values = torch.stack((image_1, image_2), 0).unsqueeze(0)\n",
    "generated_ids = beam_search_generate(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    pixel_values=pixel_values,\n",
    "    image_token_index=config.image_token_index,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    device=\"cuda\",\n",
    "    num_beams=3,\n",
    "    max_length=100,\n",
    ")\n",
    "\n",
    "# Decode to text\n",
    "captions = tokenizer.decode_batch(generated_ids)\n",
    "for caption in captions:\n",
    "    print(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12e8fe61-0a2c-4053-9fab-c141c51a74e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, tokenizer, dataloader, device, image_token_index, max_len=60, num_beams=5):\n",
    "    model.eval()\n",
    "    gts = {}\n",
    "    res = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tqdm(dataloader, desc=\"Evaluating\")):\n",
    "            input_ids, pixel_values, att_masks = batch\n",
    "            pixel_values = pixel_values.to(device)\n",
    "\n",
    "            generated_ids = beam_search_generate(\n",
    "                model,\n",
    "                tokenizer,\n",
    "                pixel_values=pixel_values,\n",
    "                image_token_index=image_token_index,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                device=device,\n",
    "                num_beams=num_beams,\n",
    "                max_length=max_len,\n",
    "            )\n",
    "\n",
    "            # Decode predictions\n",
    "            decoded_preds = tokenizer.decode_batch(generated_ids)\n",
    "            decoded_preds = [pred.strip().lower() for pred in decoded_preds]\n",
    "\n",
    "            # Decode references\n",
    "            references = input_ids\n",
    "            if isinstance(references[0], torch.Tensor):\n",
    "                references = [tokenizer.decode(ref).replace(\"<image>\", \"\").strip().lower() for ref in references]\n",
    "\n",
    "            batch_size = pixel_values.size(0)\n",
    "            for j in range(batch_size):\n",
    "                image_id = f\"img_{i * batch_size + j}\"\n",
    "                gts[image_id] = [references[j]]  # list of refs\n",
    "                res[image_id] = [decoded_preds[j]]  # model output\n",
    "            for i in range(1):\n",
    "                print(f\"Pred: {decoded_preds[i]}\")\n",
    "                print(f\"Ref: {references[i]}\")\n",
    "                print()\n",
    "\n",
    "    scores = compute_scores(gts, res)\n",
    "\n",
    "    # Optional print\n",
    "    for metric, score in scores.items():\n",
    "        print(f\"{metric.upper()}: {score:.4f}\")\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b668f14-5ff7-4489-b21c-85a9f9edbc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Java for Meteor\n",
    "# !apt-get update -y\n",
    "# !apt-get install -y openjdk-17-jre-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2609b2d7-6879-4a71-9e45-333fb39dcc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  10%|█         | 1/10 [00:07<01:05,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: <image> the lungs are clear without evidence of the lungs are clear without evidence of the lungs are clear without evidence of the lungs are clear without evidence of the lungs are clear without evidence of the cardiac monitor leads show an unchanged from prior granulomatous process the heart size and vasculature central venous catheter tip overlying external cardiac monitor leads\n",
      "Ref: <bos> the heart size and pulmonary vascularity appear within normal limits . the lungs are free of focal airspace disease . no pleural effusion or pneumothorax is seen . <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  20%|██        | 2/10 [00:13<00:52,  6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: <image> there are clear without acute bony structures show an unchanged from prior examination consists normal limits . there is a small t-spine osteophytes mediastinal contours are clear without acute bony structures show an unchanged from prior examination consists normal limits . <eos>\n",
      "Ref: <bos> lungs are clear . there is no pneumothorax or pleural effusion . the heart and mediastinum are within normal limits . bony structures are intact . <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  30%|███       | 3/10 [00:19<00:44,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: <image> status post limits . <eos>\n",
      "Ref: <bos> the lungs are clear . there is no pleural effusion or pneumothorax . the heart is not significantly enlarged . the mediastinum is normal . arthritic changes of the skeletal structures are noted . <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  40%|████      | 4/10 [00:25<00:37,  6.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: <image> the lungs are clear without evidence of the lungs are clear without evidence of the lungs are clear without evidence of the lungs are clear without evidence of the lungs are clear without evidence of the cardiac monitor leads show an unchanged from prior granulomatous process the heart size and vasculature central venous catheter tip overlying external cardiac monitor leads\n",
      "Ref: <bos> there is persistent marked enlargement of the pulmonary arteries . normal heart size . no focal airspace consolidation . no pleural effusion or pneumothorax . visualized osseous structures are unremarkable in appearance . <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  50%|█████     | 5/10 [00:31<00:31,  6.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: <image> both lungs are clear without acute bony structures show an unchanged from prior examination consists normal limits . there is a small t-spine osteophytes mediastinal contours are clear without acute bony structures show an unchanged from prior examination consists normal limits . <eos>\n",
      "Ref: <bos> the cardiomediastinal silhouette is normal in size and contour . no focal consolidation pneumothorax or large pleural effusion . normal xxxx . <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  60%|██████    | 6/10 [00:38<00:25,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: <image> the lungs are clear without evidence of the lungs are clear without evidence of the lungs are clear without evidence of the lungs are clear without evidence of the lungs are clear without evidence of the cardiac monitor leads show an unchanged from prior granulomatous process the heart size and vasculature central venous catheter tip overlying external cardiac monitor leads\n",
      "Ref: <bos> cardiomediastinal silhouette within normal limits . no acute bony abnormality . there are xxxx xxxx opacities atelectasis versus airspace disease . no large effusion or pneumothorax . <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  70%|███████   | 7/10 [00:44<00:18,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: <image> . <eos>\n",
      "Ref: <bos> the heart size and pulmonary vascularity appear within normal limits . the lungs are free of focal airspace disease . no pleural effusion or pneumothorax is seen . <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  80%|████████  | 8/10 [00:50<00:12,  6.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: <image> . <eos>\n",
      "Ref: <bos> cardiac and mediastinal contours are within normal limits . prior granulomatous disease . the lungs are clear . thoracic spondylosis . <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  90%|█████████ | 9/10 [00:57<00:06,  6.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: <image> result bronchovascular crowding as well aerated suspicious pulmonary vascularity appear within normal limits . there are clear without acute bony structures show an unchanged from prior examination consists normal limits for patient age . <eos>\n",
      "Ref: <bos> lung volumes remain low . no infiltrates . heart and pulmonary xxxx remain normal . <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 10/10 [00:58<00:00,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: <image> are clear without acute bony structures show an unchanged from prior examination consists normal limits . there is a small t-spine osteophytes mediastinal contours are clear without acute bony structures show an unchanged from prior examination consists normal limits . <eos>\n",
      "Ref: <bos> lungs are clear without focal consolidation effusion or pneumothorax . normal heart size . negative for <unk> . mild degenerative changes of the thoracic spine . <eos>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU_1: 0.1270\n",
      "BLEU_2: 0.0820\n",
      "BLEU_3: 0.0470\n",
      "BLEU_4: 0.0268\n",
      "METEOR: 0.1035\n",
      "ROUGE_L: 0.1241\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BLEU_1': 0.1269983373832917,\n",
       " 'BLEU_2': 0.08195098960400135,\n",
       " 'BLEU_3': 0.04700835898767729,\n",
       " 'BLEU_4': 0.02680478528886467,\n",
       " 'METEOR': 0.10346761761716412,\n",
       " 'ROUGE_L': np.float64(0.12414180940742026)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(DataConfig())\n",
    "\n",
    "test_loader = CustomDataLoader(\n",
    "    split=\"test\",\n",
    "    batch_size=64,\n",
    "    num_workers=1,\n",
    "    tokenizer=tokenizer,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "scores = evaluate_model(model, tokenizer, test_loader, device, image_token_index=763)\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
